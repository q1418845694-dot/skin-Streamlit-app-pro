import streamlit as st
import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import timm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import requests

# -------------------- é¡µé¢é…ç½® --------------------
st.set_page_config(
    page_title="çš®è‚¤ç—…æ™ºèƒ½è¯†åˆ« - Swin Transformer",
    page_icon="ğŸ©º",
    layout="wide"
)

st.title("ğŸ©º çš®è‚¤ç—…æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ (Swin Transformer)")
st.markdown("ä¸Šä¼ çš®è‚¤é•œå›¾åƒï¼Œæ¨¡å‹å°†é¢„æµ‹å…¶æ‰€å±çš„ç—…å˜ç±»åˆ«ã€‚")

# -------------------- æ¨¡å‹ä¸‹è½½é…ç½® --------------------
MODEL_URL = "https://huggingface.co/datasets/adjuhui/skindiseaseAI/resolve/main/best_model(1).pth"
MODEL_PATH = "best_model(1).pth"
CSV_PATH   = "Train_Ready.csv"

def download_file(url, local_filename):
    """ä»URLä¸‹è½½æ–‡ä»¶ï¼Œå¹¶æ˜¾ç¤ºè¿›åº¦æ¡"""
    if os.path.exists(local_filename):
        st.info(f"âœ… æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨ï¼š{local_filename}")
        return True
    try:
        st.info("â³ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦105MBï¼‰ï¼Œè¯·ç¨å€™...")
        response = requests.get(url, stream=True)
        response.raise_for_status()
        total_size = int(response.headers.get('content-length', 0))
        progress_bar = st.progress(0, text="ä¸‹è½½ä¸­...")
        downloaded = 0
        with open(local_filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                downloaded += len(chunk)
                if total_size:
                    percent = downloaded / total_size
                    progress_bar.progress(percent, text=f"ä¸‹è½½ä¸­ {percent:.1%}")
        progress_bar.empty()
        st.success("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        return True
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼š{e}")
        return False

# ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœæœ¬åœ°ä¸å­˜åœ¨ï¼‰
if not download_file(MODEL_URL, MODEL_PATH):
    st.stop()

# -------------------- æ£€æŸ¥ CSV æ–‡ä»¶ --------------------
if not os.path.exists(CSV_PATH):
    st.error(f"âŒ æœªæ‰¾åˆ° Train_Ready.csv æ–‡ä»¶ï¼Œè¯·å°†å…¶æ”¾ç½®åœ¨åº”ç”¨ç›®å½•ä¸‹ã€‚")
    st.stop()

# -------------------- å…¨å±€ç¼“å­˜ --------------------
@st.cache_resource
def load_model(model_path, num_classes, device):
    """åŠ è½½ Swin Transformer æ¨¡å‹"""
    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=False, num_classes=num_classes)
    # å…³é”®ï¼šweights_only=False å…¼å®¹æ—§ç‰ˆæ¨¡å‹
    state_dict = torch.load(model_path, map_location=device, weights_only=False)
    model.load_state_dict(state_dict)
    model = model.to(device)
    model.eval()
    return model

@st.cache_data
def load_class_names_from_csv(csv_file):
    """ä»è®­ç»ƒæ—¶ä½¿ç”¨çš„ CSV æ–‡ä»¶ä¸­æå–ç±»åˆ«åç§°ï¼ˆä¸è®­ç»ƒæ—¶é¡ºåºä¸€è‡´ï¼‰"""
    df = pd.read_csv(csv_file)
    classes = sorted(list(df['Label'].unique()))   # è®­ç»ƒæ—¶ä¹Ÿæ˜¯ sorted
    return classes

# -------------------- åŠ è½½ç±»åˆ« --------------------
class_names = load_class_names_from_csv(CSV_PATH)

# -------------------- åŠ è½½æ¨¡å‹ --------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = load_model(MODEL_PATH, len(class_names), device)

st.sidebar.markdown("### âš™ï¸ ç³»ç»Ÿä¿¡æ¯")
st.sidebar.markdown(f"ç±»åˆ«æ•°é‡: {len(class_names)}")
st.sidebar.markdown(f"è¿è¡Œè®¾å¤‡: `{device}`")

# -------------------- å›¾åƒé¢„å¤„ç† --------------------
val_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# -------------------- ä¸»ç•Œé¢ --------------------
col1, col2 = st.columns([1, 1])

with col1:
    uploaded_img = st.file_uploader(
        "ğŸ“¤ ä¸Šä¼ çš®è‚¤é•œå›¾åƒ",
        type=['jpg', 'jpeg', 'png', 'bmp', 'tiff'],
        help="æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼"
    )
    if uploaded_img is not None:
        image = Image.open(uploaded_img).convert('RGB')
        st.image(image, caption="åŸå§‹å›¾åƒ", use_column_width=True)

if uploaded_img is not None:
    with col2:
        st.subheader("ğŸ” é¢„æµ‹ç»“æœ")

        input_tensor = val_transform(image).unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = F.softmax(outputs, dim=1)
            top5_prob, top5_idx = torch.topk(probabilities, 5)

        top5_prob = top5_prob.cpu().numpy()[0]
        top5_idx  = top5_idx.cpu().numpy()[0]
        top5_labels = [class_names[i] for i in top5_idx]

        st.markdown(f"### ğŸ¥‡ é¢„æµ‹: **{top5_labels[0]}**")
        st.markdown(f"ç½®ä¿¡åº¦: **{top5_prob[0]:.2%}**")

        # Top-5 æ¡å½¢å›¾
        fig, ax = plt.subplots(figsize=(6, 3))
        colors = sns.color_palette("Blues_d", len(top5_prob))
        y_pos = np.arange(len(top5_labels))
        ax.barh(y_pos, top5_prob, color=colors)
        ax.set_yticks(y_pos)
        ax.set_yticklabels(top5_labels, fontsize=10)
        ax.invert_yaxis()
        ax.set_xlabel("ç½®ä¿¡åº¦")
        ax.set_title("Top-5 é¢„æµ‹")
        ax.set_xlim(0, 1)
        for i, (prob, label) in enumerate(zip(top5_prob, top5_labels)):
            ax.text(prob + 0.01, i, f"{prob:.2%}", va='center')
        st.pyplot(fig)

        # å±•å¼€æ˜¾ç¤º Top-10
        with st.expander("ğŸ“Š æŸ¥çœ‹æ‰€æœ‰ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒ"):
            all_prob = probabilities.cpu().numpy()[0]
            sorted_indices = np.argsort(all_prob)[::-1]
            sorted_labels = [class_names[i] for i in sorted_indices[:10]]
            sorted_probs = all_prob[sorted_indices[:10]]

            fig2, ax2 = plt.subplots(figsize=(8, 4))
            ax2.barh(np.arange(len(sorted_labels)), sorted_probs, color='lightcoral')
            ax2.set_yticks(np.arange(len(sorted_labels)))
            ax2.set_yticklabels(sorted_labels, fontsize=9)
            ax2.invert_yaxis()
            ax2.set_xlabel("ç½®ä¿¡åº¦")
            ax2.set_title("Top-10 ç±»åˆ«")
            ax2.set_xlim(0, 1)
            st.pyplot(fig2)

else:
    with col2:
        st.info("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ ä¸€å¼ çš®è‚¤å›¾åƒ")

st.markdown("---")
st.markdown("""
**ä½¿ç”¨è¯´æ˜**  
è¯·ä¸Šä¼ æ‚¨çš„å‘ç—…éƒ¨ä½çš„æ¸…æ™°å›¾ç‰‡ï¼Œç³»ç»Ÿå°†ä¸ºæ‚¨è¯Šæ–­å‡ºæœ€å¯èƒ½çš„çš®è‚¤ç—…ç±»å‹  
""")
